# 테스트 결과 해석 방법

## k6 결과 개요

k6 부하 테스트 결과는 다양한 메트릭을 제공하며, 이를 통해 시스템의 성능을 분석할 수 있습니다. 주요 메트릭은 다음과 같습니다:

### 주요 지표

1. **http_reqs**: 총 HTTP 요청 수
2. **http_req_duration**: HTTP 요청 처리 시간 (밀리초)
3. **http_req_failed**: 실패한 HTTP 요청 비율
4. **iterations**: 테스트 시나리오 반복 실행 횟수
5. **vus**: 동시에 활성화된 가상 사용자 수
6. **data_received / data_sent**: 수신/송신 데이터 양

### 백분위수 해석

각 지표는 다음 백분위수로 표시됩니다:

- **p(95)**: 95% 응답 시간. 모든 요청 중 95%가 이 시간 내에 완료됨
- **p(99)**: 99% 응답 시간. 모든 요청 중 99%가 이 시간 내에 완료됨
- **avg**: 평균 응답 시간
- **min / max**: 최소/최대 응답 시간
- **med**: 중앙값 응답 시간

## 그라파나 대시보드 분석

### 1. HTTP 요청 성공률 패널

![HTTP 요청 성공률]

**성공적인 결과 기준**:

- 초당 목표 요청 수(RPS) 달성
- 안정적인 그래프 패턴 (급격한 변동 없음)
- 부하 증가에 따른 선형적 증가

**문제 식별**:

- 갑작스러운 그래프 하락은 서비스 포화 상태 의미
- 요청 성공률 95% 미만은 조사 필요

### 2. HTTP 응답 시간 패널

![HTTP 응답 시간]

**성공적인 결과 기준**:

- p(95) 응답 시간이 SLA 기준 이하
- 시간 경과에 따른 안정적인 응답 시간
- 부하 증가 시에도 급격한 상승 없음

**문제 식별**:

- 갑작스러운 응답 시간 증가는 성능 병목 의미
- 응답 시간이 특정 엔드포인트에서만 증가하면 해당 코드 검토 필요
- 점진적인 응답 시간 증가는 메모리 누수 가능성

### 3. HTTP 요청 실패율 패널

![HTTP 요청 실패율]

**성공적인 결과 기준**:

- 1% 미만의 실패율
- 부하 증가에도 실패율 낮게 유지

**문제 식별**:

- 실패율 급증은 서비스 오류 또는 타임아웃 의미
- 특정 시점의 실패율 증가는 외부 의존성 문제 가능성
- 특정 상태 코드가 많이 나타나면 해당 오류 유형 조사

### 4. 가상 사용자 수 패널

![가상 사용자 수]

**성공적인 결과 기준**:

- 계획된 VU 수 달성
- 시나리오별 적절한 VU 분포

**문제 식별**:

- 계획된 VU보다 낮은 수치는 리소스 제약 또는 스크립트 오류 가능성
- VU 수 급변은 테스트 실행 문제 암시

### 5. 서비스 CPU 사용률 패널

![서비스 CPU 사용률]

**성공적인 결과 기준**:

- 최대 부하에서 70% 미만 CPU 사용률
- 부하 증가에 따른 선형적 증가
- 서비스 간 균등한 부하 분산

**문제 식별**:

- 80% 이상 지속 사용은 CPU 병목 현상 의미
- 특정 서비스만 높은 CPU 사용률은 최적화 필요 암시
- 부하와 상관없는 갑작스러운 CPU 스파이크는 비효율적 코드 또는 메모리 누수 의미

### 6. 서비스 메모리 사용량 패널

![서비스 메모리 사용량]

**성공적인 결과 기준**:

- 안정적인 메모리 사용 패턴
- 테스트 종료 후 초기 수준으로 회복

**문제 식별**:

- 지속적으로 증가하는 메모리 사용량은 메모리 누수 의미
- 갑작스러운 메모리 사용량 증가는 대용량 요청 또는 캐싱 문제 가능성
- 반복적인 메모리 패턴(톱니 모양)은 가비지 컬렉션 부하 의미

## 성능 병목 현상 분석

### 1. 응답 시간 병목

응답 시간이 급격히 증가하는 경우 다음을 확인하세요:

- **데이터베이스 쿼리**: 느린 쿼리, 인덱스 부족, 연결 풀 고갈
- **외부 서비스 통합**: 타사 API 응답 지연
- **서버 리소스**: CPU, 메모리, 디스크 I/O 포화
- **네트워크**: 대역폭 제한, 지연 시간 증가
- **애플리케이션 코드**: 비효율적 알고리즘, 병렬 처리 부족

### 2. 처리량 병목

초당 요청 수(RPS)가 더 이상 증가하지 않는 경우:

- **스레드 풀 고갈**: 요청 대기열 증가
- **CPU 포화**: 100%에 가까운 CPU 사용률
- **I/O 제한**: 디스크 또는 네트워크 I/O 한계
- **데이터베이스 연결 제한**: 연결 풀 고갈
- **서비스 수평적 확장 필요**: 인스턴스 수 증가 고려

### 3. 오류율 분석

오류가 증가하는 경우 오류 유형을 확인하세요:

- **4xx 오류**: 클라이언트 요청 문제 (검증, 인증)
- **5xx 오류**: 서버 내부 오류
- **타임아웃**: 요청 처리 시간 초과
- **연결 오류**: 서비스 간 통신 문제

## 다양한 시나리오 해석

### 1. 로그인 시나리오

**성공 기준**:

- p(95) 응답 시간 < 200ms
- 실패율 < 0.5%
- 목표 RPS 달성

**주의 지표**:

- 인증 서비스 CPU 사용률
- JWT 토큰 생성 시간
- 데이터베이스 조회 시간

### 2. 이벤트 생성 시나리오

**성공 기준**:

- p(95) 응답 시간 < 250ms
- 실패율 < 1%
- 데이터베이스 쓰기 일관성

**주의 지표**:

- 이벤트 서비스 메모리 사용량
- 데이터베이스 쓰기 지연 시간
- 관련 서비스 통신 시간

### 3. 보상 요청 시나리오

**성공 기준**:

- p(95) 응답 시간 < 150ms
- 실패율 < 1%
- 일관된 보상 상태 업데이트

**주의 지표**:

- 동시 요청 처리 능력
- 데이터베이스 락 경합
- 서비스 간 메시지 전달 시간

## 개선 가능성 식별

테스트 결과를 바탕으로 다음과 같은 개선 사항을 고려하세요:

### 1. 애플리케이션 수준

- **코드 최적화**: 병목 지점 식별 및 개선
- **캐싱 도입**: 자주 요청되는 데이터 캐싱
- **비동기 처리**: 블로킹 작업을 비동기로 전환
- **데이터베이스 최적화**: 인덱스 추가, 쿼리 개선
- **서비스 분리**: 과부하 서비스 분리 또는 확장

### 2. 인프라 수준

- **리소스 확장**: CPU, 메모리 증설
- **수평적 확장**: 서비스 인스턴스 추가
- **로드 밸런싱 개선**: 더 효율적인 부하 분산
- **데이터베이스 샤딩**: 데이터 분산 저장
- **CDN 활용**: 정적 콘텐츠 배포 최적화

### 3. 아키텍처 수준

- **마이크로서비스 세분화**: 과부하 서비스 분리
- **이벤트 기반 아키텍처**: 비동기 통신으로 전환
- **CQRS 패턴**: 읽기/쓰기 작업 분리
- **캐시 계층**: Redis 또는 Memcached 도입
- **서비스 메시**: 서비스 간 통신 최적화

## 장기적 모니터링 전략

지속적인 성능 모니터링을 위한 방안:

- **정기적 부하 테스트**: 주요 변경 사항 배포 전/후 테스트
- **성능 지표 수집**: 중요 지표 지속적 모니터링
- **알림 설정**: 성능 저하 시 즉시 알림
- **트렌드 분석**: 시간 경과에 따른 성능 변화 추적
- **자동화된 CI/CD 통합**: 빌드 파이프라인에 성능 테스트 통합

## 결론

k6 부하 테스트 결과는 시스템의 현재 성능뿐만 아니라 잠재적인 병목 현상과 개선 가능성을 식별하는 데 중요한 도구입니다. 지속적인 테스트와 분석을 통해 사용자 경험 향상과 시스템 안정성을 보장할 수 있습니다.
